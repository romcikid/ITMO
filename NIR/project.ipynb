{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5247e45f55a724347f31ab43ea75ee4f523c78b9ed6e2d1c62d227887969829b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Подлючение необходимых библиотек."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import BDeuScore, K2Score, BicScore\n",
    "from pgmpy.estimators import PC,HillClimbSearch\n",
    "from pomegranate import *\n",
    "import seaborn as sns\n",
    "from sklearn import *\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import time"
   ]
  },
  {
   "source": [
    "<h2>Подготовка данных</h2>\n",
    "\n",
    "Считывание изначального датасета."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_data = pd.read_excel('dataset_geologist.xlsx')\n",
    "geo_data.head()"
   ]
  },
  {
   "source": [
    "Считывание датасета со значениями пропущенных в датасете geo_data данных."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_data = pd.read_csv('missimg_values.csv', sep=';')\n",
    "mis_data.head()"
   ]
  },
  {
   "source": [
    "Составление тестовой выборки из двух предыдущих."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = geo_data.copy()\n",
    "table = mis_data[['Unnamed: 0']].copy()\n",
    "size_of_table = len(table)\n",
    "i = 0\n",
    "\n",
    "while size_of_table > 0:\n",
    "    if test_data.values[i,1] == table.values[0,0]:\n",
    "        table = table.drop(table.index[[0]])\n",
    "        size_of_table = len(table)\n",
    "        i+=1\n",
    "    else:\n",
    "        test_data = test_data.drop(test_data.index[[i]])\n",
    "\n",
    "    if size_of_table == 0:\n",
    "        k = i\n",
    "\n",
    "        while len(test_data) > i:\n",
    "            test_data = test_data.drop(test_data.index[[k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data[['14. Depth (top reservoir ft TVD)', '17. Thickness (gross average ft)', '18. Thickness (net pay average ft)', '19. Porosity (matrix average %)',\t'20. Permeability (air average mD)', '13. Structural setting', '15. Reservoir period', '16. Lithology (main)', '6. Tectonic regime', '11. Hydrocarbon type (main)']]\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(columns=['19. Porosity (matrix average %)','6. Tectonic regime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['13. Structural setting', '15. Reservoir period', '16. Lithology (main)','11. Hydrocarbon type (main)']:\n",
    "     lee = preprocessing.LabelEncoder()\n",
    "     test_data[column] = lee.fit_transform(test_data[column].astype(str))\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "source": [
    "Если установить стратегию на 'kmeans', то предсказание '6. Tectonic regime становится точнее'.\n",
    "\n",
    "Если установить стратегию на 'quantile', то предсказание '19. Porosity (matrix average %)' становится точнее."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testformed_data = test_data.copy()\n",
    "est = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "data_discrete = est.fit_transform(test_data.values[:,[0,1,2,3]])\n",
    "testformed_data[['14. Depth (top reservoir ft TVD)', '17. Thickness (gross average ft)', '18. Thickness (net pay average ft)', '20. Permeability (air average mD)']] = data_discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testformed_data.head()"
   ]
  },
  {
   "source": [
    "Составление тренировочной выборки."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = geo_data.copy()\n",
    "train_data = train_data.dropna()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[['14. Depth (top reservoir ft TVD)', '17. Thickness (gross average ft)', '18. Thickness (net pay average ft)', '19. Porosity (matrix average %)', '20. Permeability (air average mD)', '13. Structural setting', '15. Reservoir period', '16. Lithology (main)', '6. Tectonic regime', '11. Hydrocarbon type (main)']]\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leun = 0\n",
    "for column in ['13. Structural setting', '15. Reservoir period', '16. Lithology (main)', '6. Tectonic regime', '11. Hydrocarbon type (main)']:\n",
    "     le = preprocessing.LabelEncoder()\n",
    "     if column == '6. Tectonic regime':\n",
    "          leun = le\n",
    "     train_data[column] = le.fit_transform(train_data[column].astype(str))\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsformed_data = train_data.copy()\n",
    "est = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "data_discrete = est.fit_transform(train_data.values[:,0:5])\n",
    "trainsformed_data[['14. Depth (top reservoir ft TVD)', '17. Thickness (gross average ft)', '18. Thickness (net pay average ft)', '19. Porosity (matrix average %)', '20. Permeability (air average mD)']] = data_discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsformed_data.head()"
   ]
  },
  {
   "source": [
    "Основными параметрами выборок были выбраны:\n",
    "- Depth - Глубина -\n",
    "- Gross - Плотность -\n",
    "- Net pay\n",
    "- Porosity - Пористость -\n",
    "- Permeability - Проницаемость -\n",
    "- Structural setting - Структурная установка\n",
    "- Reservoir period - Период резервуара\n",
    "- Lithology - Литология\n",
    "- Tectonic regime - Тектонический режим\n",
    "- Hydrocarbon type - Углеводородный тип"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h2>Построение корреляционной матрицы</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#отбор столбцов для построения корреляционной матрицы\n",
    "x_train = trainsformed_data\n",
    "\n",
    "#построение диагональной маски\n",
    "mask = np.zeros_like(x_train.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "sns.heatmap(x_train.corr(), mask = mask, annot=True, fmt= '.1f', ax = ax, cmap = 'Blues')"
   ]
  },
  {
   "source": [
    "<h2>Hill Climb Search</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "В сравнении метода hill climbing search исользуются методы оценки:\n",
    "\n",
    "<h3>K2 Score</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc1 = HillClimbSearch(trainsformed_data, scoring_method=K2Score(trainsformed_data))"
   ]
  },
  {
   "source": [
    "<h3>BDeu Score</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc2 = HillClimbSearch(trainsformed_data, scoring_method=BDeuScore(trainsformed_data))"
   ]
  },
  {
   "source": [
    "<h3>Bic Score</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc3 = HillClimbSearch(trainsformed_data, scoring_method=BicScore(trainsformed_data))"
   ]
  },
  {
   "source": [
    "<h2>Оценка структуры данных</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "model1 = hc1.estimate()\n",
    "print('\\n Время выполнения: ', time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "model2 = hc2.estimate()\n",
    "print('\\n Время выполнения: ', time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "model3 = hc3.estimate()\n",
    "print('\\n Время выполнения: ', time.time()-tic)"
   ]
  },
  {
   "source": [
    "<h2>Проверка построенных структур данных</h2>\n",
    "\n",
    "Как выяснилось, они одинаковые :)\n",
    "<h2>Должны быть разные</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_K1 = nx.DiGraph()\n",
    "G_K1.add_edges_from(model1.edges())\n",
    "pos = nx.layout.circular_layout(G_K1)\n",
    "nx.draw(G_K1, pos, node_size=60, font_size=6, with_labels=True,font_weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_K2 = nx.DiGraph()\n",
    "G_K2.add_edges_from(model2.edges())\n",
    "pos = nx.layout.circular_layout(G_K2)\n",
    "nx.draw(G_K2, pos, node_size=5, font_size=7, with_labels=True,font_weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_K3 = nx.DiGraph()\n",
    "G_K3.add_edges_from(model3.edges())\n",
    "pos = nx.layout.circular_layout(G_K3)\n",
    "nx.draw(G_K3, pos, node_size=60, font_size=6, with_labels=True,font_weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание байесовской модели.\n",
    "bn1 = BayesianModel(model1.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание байесовской модели.\n",
    "bn2 = BayesianModel(model2.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание байесовской модели.\n",
    "bn3 = BayesianModel(model3.edges())"
   ]
  },
  {
   "source": [
    "<h2>Обучение байесовских сетей</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "# Обучение байесовской сети.\n",
    "bn1.fit(trainsformed_data)\n",
    "print('\\n Время выполнения: ', time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "# Обучение байесовской сети.\n",
    "bn2.fit(trainsformed_data)\n",
    "print('\\n Время выполнения: ', time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "# Обучение байесовской сети.\n",
    "bn3.fit(trainsformed_data)\n",
    "print('\\n Время выполнения: ', time.time()-tic)"
   ]
  },
  {
   "source": [
    "<h2>Заполнение пропусков</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "tic = time.time()\n",
    "# Заполнение пропусков\n",
    "result_data1 = bn1.predict(testformed_data)\n",
    "print('\\n Время выполнения: ', time.time()-tic)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "# Заполнение пропусков\n",
    "result_data2 = bn2.predict(testformed_data)\n",
    "print('\\n Время выполнения: ', time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "# Заполнение пропусков\n",
    "result_data3 = bn3.predict(testformed_data)\n",
    "print('\\n Время выполнения: ', time.time()-tic)"
   ]
  },
  {
   "source": [
    "<h2>Проверка предсказанных значений</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data3.head()"
   ]
  },
  {
   "source": [
    "<h2>Подсчет точности заполнения пропусков сетями</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data1.reset_index(drop=True, inplace=True)\n",
    "testformed_data.reset_index(drop=True, inplace=True)\n",
    "concat_data = result_data1[['19. Porosity (matrix average %)']]\n",
    "concat_data = pd.concat([testformed_data[['14. Depth (top reservoir ft TVD)', '17. Thickness (gross average ft)', '18. Thickness (net pay average ft)', '20. Permeability (air average mD)']], concat_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porosity = est.inverse_transform(concat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(porosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = 0\n",
    "for i in range(len(porosity)):\n",
    "    print(porosity[i,4], mis_data.values[i,4])\n",
    "    error += (porosity[i,4]-mis_data.values[i,4])**2\n",
    "\n",
    "error = error / len(porosity)\n",
    "print('\\n Средневкадратическая ошибка: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data2.reset_index(drop=True, inplace=True)\n",
    "concat_data = result_data2[['19. Porosity (matrix average %)']]\n",
    "concat_data = pd.concat([testformed_data[['14. Depth (top reservoir ft TVD)', '17. Thickness (gross average ft)', '18. Thickness (net pay average ft)', '20. Permeability (air average mD)']], concat_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porosity = est.inverse_transform(concat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = 0\n",
    "for i in range(len(porosity)):\n",
    "    print(porosity[i,4], mis_data.values[i,4])\n",
    "    error += (porosity[i,4]-mis_data.values[i,4])**2\n",
    "\n",
    "error = error / len(porosity)\n",
    "print('\\n Средневкадратическая ошибка: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data3.reset_index(drop=True, inplace=True)\n",
    "concat_data = result_data3[['19. Porosity (matrix average %)']]\n",
    "concat_data = pd.concat([testformed_data[['14. Depth (top reservoir ft TVD)', '17. Thickness (gross average ft)', '18. Thickness (net pay average ft)', '20. Permeability (air average mD)']], concat_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porosity = est.inverse_transform(concat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = 0\n",
    "for i in range(len(porosity)):\n",
    "    print(porosity[i,4], mis_data.values[i,4])\n",
    "    error += (porosity[i,4]-mis_data.values[i,4])**2\n",
    "\n",
    "error = error / len(porosity)\n",
    "print('\\n Средневкадратическая ошибка: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regime1 = leun.inverse_transform(result_data1.values[:,1].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regime2 = leun.inverse_transform(result_data2.values[:,1].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regime3 = leun.inverse_transform(result_data3.values[:,1].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_false(mis_data: pd.DataFrame, regime: pd.DataFrame):\n",
    "    true, false = 0, 0\n",
    "\n",
    "    for i in range(len(regime)):\n",
    "        print(regime[i], mis_data.values[i,9], regime[i] in mis_data.values[i,9])\n",
    "        if regime[i] in mis_data.values[i,9]:\n",
    "            true += 1\n",
    "        else:\n",
    "            false += 1\n",
    "    \n",
    "    print('Число совпадений: ', true)\n",
    "    print('Число промахов: ', false)\n",
    "    \n",
    "    ax = sns.barplot(x=['True','False'], y=[true, false])\n",
    "    ax.set(xlabel='Значения', ylabel='n')\n",
    "\n",
    "    plt.legend(handles=[true, false])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_false(mis_data,regime1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_false(mis_data,regime2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_false(mis_data,regime3)"
   ]
  },
  {
   "source": [
    "<h2>Нахождение среднего, максимального и минимального времен построения модели</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# md_times = []\n",
    "# max_times = []\n",
    "# min_times = []\n",
    "# bn_times = []\n",
    "\n",
    "# for i in range(3):\n",
    "#      bn_times.append([])\n",
    "\n",
    "# for i in range(100):\n",
    "#      tic = time.time()\n",
    "#      bn1.fit(trainsformed_data)\n",
    "#      bn_times[0].append(time.time() - tic)\n",
    "#      tic = time.time()\n",
    "#      bn2.fit(trainsformed_data)\n",
    "#      bn_times[1].append(time.time() - tic)\n",
    "#      tic = time.time()\n",
    "#      bn3.fit(trainsformed_data)\n",
    "#      bn_times[2].append(time.time() - tic)\n",
    "\n",
    "# for i in range(3):\n",
    "#      max_times.append(max(bn_times[i]))\n",
    "#      min_times.append(min(bn_times[i]))\n",
    "#      md_times.append(sum(bn_times[i])/len(bn_times[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def give_barplot(var):\n",
    "#      sns.barplot(x=['K2Score','BDeuScore','BicScore'], y=var)\n",
    "#      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give_barplot(max_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give_barplot(min_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give_barplot(md_times)"
   ]
  },
  {
   "source": [
    "<h2>PC algorithm</h2>\n",
    "\n",
    "Не работает, потому что при построении модели куда-то теряется параметр :(\n",
    "\n",
    "<h2>Создание модели</h2>."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PC(trainsformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "model = pc.estimate()\n",
    "print('\\n Время выполнения: ', time.time()-tic)"
   ]
  },
  {
   "source": [
    "<h2>Оценка структуры данных</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_K2 = nx.DiGraph()\n",
    "G_K2.add_edges_from(model.edges())\n",
    "pos = nx.layout.circular_layout(G_K2)\n",
    "nx.draw(G_K2, pos, node_size=10, font_size=7, with_labels=True,font_weight='bold')"
   ]
  },
  {
   "source": [
    "<h2>Создание байесовской сети</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Создание байесовской модели.\n",
    "bn = BayesianModel(model.edges())"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "<h2>Обучение сетей</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "# Обучение параметров.\n",
    "bn.fit(trainsformed_data)\n",
    "print('\\n Время выполнения: ', time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "# Заполнение пропусков\n",
    "result_data = bn.predict(testformed_data)\n",
    "print('\\n Время выполнения: ', time.time()-tic)"
   ]
  },
  {
   "source": [
    "<h2>Подсчет точности заполнения пропусков сетями</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data.reset_index(drop=True, inplace=True)\n",
    "concat_data = result_data[['19. Porosity (matrix average %)']]\n",
    "concat_data = pd.concat([testformed_data[['14. Depth (top reservoir ft TVD)', '17. Thickness (gross average ft)', '18. Thickness (net pay average ft)', '20. Permeability (air average mD)']], concat_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porosity = est.inverse_transform(concat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = 0\n",
    "for i in range(len(porosity)):\n",
    "     print(porosity[i,4], mis_data.values[i,4])\n",
    "     error += (porosity[i,4]-mis_data.values[i,4])**2\n",
    "\n",
    "error = error / len(porosity)\n",
    "print('\\n Средневкадратическая ошибка: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regime2 = leun.inverse_transform(result_data2.values[:,1].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_false(mis_data,regime2)"
   ]
  },
  {
   "source": [
    "<h2>Tree search</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import TreeSearch\n",
    "best = TreeSearch(trainsformed_data, root_node='19. Porosity (matrix average %)')\n",
    "model = best.estimate(estimator_type='chow-liu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_K2 = nx.DiGraph()\n",
    "G_K2.add_edges_from(model.edges())\n",
    "pos = nx.layout.circular_layout(G_K2)\n",
    "nx.draw(G_K2, pos, node_size=60, font_size=6, with_labels=True,font_weight='bold')"
   ]
  },
  {
   "source": [
    "<h2>Создание байесовской сети</h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание байесовской модели.\n",
    "bn = BayesianModel(model.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "# Обучение байесовской сети.\n",
    "bn.fit(trainsformed_data)\n",
    "print('\\n Время выполнения: ', time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "# Заполнение пропусков\n",
    "result_data = bn.predict(testformed_data)\n",
    "print('\\n Время выполнения: ', time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data.reset_index(drop=True, inplace=True)\n",
    "testformed_data.reset_index(drop=True, inplace=True)\n",
    "concat_data = result_data1[['19. Porosity (matrix average %)']]\n",
    "concat_data = pd.concat([testformed_data[['14. Depth (top reservoir ft TVD)', '17. Thickness (gross average ft)', '18. Thickness (net pay average ft)', '20. Permeability (air average mD)']], concat_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porosity = est.inverse_transform(concat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "error = 0\n",
    "for i in range(len(porosity)):\n",
    "    print(porosity[i,4], mis_data.values[i,4])\n",
    "    error += abs(porosity[i,4]-mis_data.values[i,4])\n",
    "\n",
    "error = error / len(porosity)\n",
    "print('\\n Средняя ошибка: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regime = leun.inverse_transform(result_data.values[:,1].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_false(mis_data,regime)"
   ]
  },
  {
   "source": [
    "Посмотреть реализации для гетерогенных сетей."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}